# STEP 3 — MODELING: LOGISTIC REGRESSION

# Load libraries
library(tidyverse)
library(caret)
library(pROC)
library(randomForest)

set.seed(123)

# 1. Load cleaned dataset
df <- read.csv("C:/Users/neplu/Downloads/hospital readmission_r/data/processed/diabetes_processed.csv")
df$readmitted_30 <- factor(df$readmitted_30, levels = c("NO", "YES"))

# 2. Drop ID columns + outcome duplication
id_cols <- c("encounter_id", "patient_nbr", "readmitted")
id_cols <- id_cols[id_cols %in% colnames(df)]

df_model <- df %>%
  select(-all_of(id_cols)) %>%
  drop_na()

# 3. Train/test split
set.seed(123)
train_index <- createDataPartition(df_model$readmitted_30, p = 0.7, list = FALSE)

train <- df_model[train_index, ]
test  <- df_model[-train_index, ]

# 4. Convert character → factor
train <- train %>% mutate(across(where(is.character), as.factor))
test  <- test  %>% mutate(across(where(is.character), as.factor))

#  Drop predictors with <2 unique values (cannot be used in regression)
predictor_names <- setdiff(names(train), "readmitted_30")

n_levels <- sapply(train[predictor_names], function(x) {
  if (is.factor(x)) {
    nlevels(x)
  } else {
    length(unique(x))
  }
})

cols_to_drop <- names(n_levels[n_levels < 2])
cols_to_drop   # shows what gets dropped

train <- train %>% select(-all_of(cols_to_drop))
test  <- test  %>% select(-all_of(cols_to_drop))

#  Use a smaller sample for logistic regression (because full dataset is heavy)
set.seed(123)
train_small <- train %>% sample_n(20000)

# 5. Logistic Regression (FAST VERSION)
model_logit <- glm(
  readmitted_30 ~ time_in_hospital + num_lab_procedures + num_medications + number_diagnoses +
    age + race + gender + admission_type_id + discharge_disposition_id + admission_source_id,
  data = train_small,
  family = binomial
)

summary(model_logit)

# Predictions on full test set
pred_logit_prob <- predict(model_logit, newdata = test, type = "response")

pred_logit_class <- ifelse(pred_logit_prob >= 0.5, "YES", "NO")
pred_logit_class <- factor(pred_logit_class, levels = c("NO", "YES"))

# Confusion matrix
cm_logit <- confusionMatrix(pred_logit_class, test$readmitted_30, positive = "YES")
cm_logit

#  ROC + AUC
roc_logit <- roc(test$readmitted_30, pred_logit_prob)
auc_logit <- auc(roc_logit)
auc_logit



#6. Random Forest
cat("\n=== Random Forest ===\n")

# make sure factors are properly set
train_rf <- train_small  # use the 20k sample for speed
test_rf  <- test

train_rf <- train_rf %>%
  mutate(across(where(is.character), as.factor))

test_rf <- test_rf %>%
  mutate(across(where(is.character), as.factor))

# use the SAME predictors as logistic regression (no crazy 100-level factors)
rf_formula <- readmitted_30 ~ time_in_hospital + num_lab_procedures + num_medications + number_diagnoses +
  age + race + gender + admission_type_id + discharge_disposition_id + admission_source_id

model_rf <- randomForest(
  rf_formula,
  data = train_rf,
  ntree = 200,
  mtry = 4,
  importance = TRUE
)

print(model_rf)

# Predict on test set
pred_rf_prob <- predict(model_rf, newdata = test_rf, type = "prob")[, "YES"]
pred_rf_class <- predict(model_rf, newdata = test_rf, type = "response")

# Confusion matrix
cm_rf <- confusionMatrix(pred_rf_class, test_rf$readmitted_30, positive = "YES")
cm_rf

# ROC and AUC
roc_rf <- roc(test_rf$readmitted_30, pred_rf_prob)
auc_rf <- auc(roc_rf)
auc_rf


#7. Variable importance (Random Forest)

cat("\n=== Random Forest Variable Importance ===\n")

vip <- importance(model_rf)
vip_df <- as.data.frame(vip) %>%
  rownames_to_column(var = "variable") %>%
  arrange(desc(MeanDecreaseGini))

print(head(vip_df, 20))

# Save importance to CSV
out_dir <- "C:/Users/neplu/Downloads/hospital readmission_r/outputs/models"
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

write.csv(vip_df, file.path(out_dir, "rf_variable_importance.csv"), row.names = FALSE)

# Simple plot of top 20 variables
ggplot(vip_df[1:20, ], aes(x = reorder(variable, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Top 20 Important Predictors (Random Forest)",
    x = "Variable",
    y = "Mean Decrease Gini"
  )



dir.create("C:/Users/neplu/Downloads/hospital readmission_r/outputs/plots",
           recursive = TRUE,
           showWarnings = FALSE)

file.exists("C:/Users/neplu/Downloads/hospital readmission_r/outputs/plots")

ggsave(
  filename = "rf_variable_importance_top20.png",
  path = "C:/Users/neplu/Downloads/hospital readmission_r/outputs/plots",
  width = 8,
  height = 6,
  dpi = 300
)

